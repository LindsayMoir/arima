{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads the data from the John Hopkins dataset. The best way is to make sure that you have the current version of the data by cloning the repository from John Hokins at this url https://github.com/CSSEGISandData/COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_columns(arg_dict):\n",
    "    \"\"\"Columns have changed over time. Need to get the largest possible number of column names\"\"\"\n",
    "    \n",
    "    all_files = glob.glob(arg_dict['path'] + \"/*.csv\")\n",
    "\n",
    "    li_set = {}\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, nrows=1) # Just want the header\n",
    "        cols = df.columns\n",
    "        cols = set(cols)\n",
    "        li_set = cols.union(li_set)\n",
    "\n",
    "    return li_set, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(all_df_cols, arg_dict):\n",
    "    \"\"\"Gets the data from the John Hopkins directory which is stored locally\"\"\"\n",
    "\n",
    "    all_files = glob.glob(arg_dict['path'] + \"/*.csv\")\n",
    "\n",
    "    li = []\n",
    "\n",
    "    for filename in all_files:\n",
    "\n",
    "        # Read in the next csv\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        # Get the date of the file\n",
    "        date_string = filename[-14:-4]\n",
    "\n",
    "        # Insert the date_string into the first column of the df\n",
    "        df.insert(0, \"Date_\", date_string) \n",
    "\n",
    "        # If it is a full df then just append it\n",
    "        if df.shape[1] == 13:\n",
    "            li.append(df)\n",
    "\n",
    "        else:\n",
    "            # Need to build a df that is the same number of columns as the largest df (last one)\n",
    "            # Create a temp_df to hold everything\n",
    "            temp_df = pd.DataFrame(data=np.nan, columns=all_df_cols.insert(0, 'Date_'), index=df.index)\n",
    "\n",
    "            # Call function to create the short_df\n",
    "            df = short_df(df, temp_df)\n",
    "\n",
    "            # append df to li\n",
    "            li.append(df)\n",
    "\n",
    "    return pd.concat(li)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_df(df, temp_df):\n",
    "    \"\"\"Takes the columns from the 'short df' and puts them in a temp df.\n",
    "    This temp_df will later be put into a df with other columns.\"\"\"\n",
    "    \n",
    "    # Pandas really does not like '/' or ' ' in a column name so ... time to rename\n",
    "    df.rename(columns={'Province/State': 'Province_State', \n",
    "                       'Country/Region': 'Country_Region',\n",
    "                       'Last Update': 'Last_Update',\n",
    "                       'Latitude': 'Lat',\n",
    "                       'Longitude': 'Long_'}, inplace=True)\n",
    "    \n",
    "    # Get the current_df columns\n",
    "    cols = df.columns\n",
    "    \n",
    "    # For loop for putting the appropriate columns in temp_df\n",
    "    for col in cols:\n",
    "        temp_df[col] = df[col]\n",
    "        \n",
    "    return temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_index_write(all_df, arg_dict):\n",
    "    \"\"\"Resets the index, changes Data_ to datetime format, and writes all_df to disk\"\"\"\n",
    "    \n",
    "    # reset the index\n",
    "    all_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Convert Date_ column to date\n",
    "    all_df['Date_'] =  pd.to_datetime(all_df['Date_'], infer_datetime_format=True)\n",
    "    \n",
    "    # Write to disk\n",
    "    all_df.to_csv(arg_dict['file_name_1'])\n",
    "    \n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver(arg_dict):\n",
    "    \"\"\"Driver program\"\"\"\n",
    "    \n",
    "    # Columns are changing over time. Get the right column names.\n",
    "    li_set, all_df_cols = get_all_columns(arg_dict)\n",
    "    \n",
    "    # Get all of the csv files in the right format and return the df\n",
    "    df = get_data(all_df_cols, arg_dict)\n",
    "    \n",
    "    # A couple of fixes required to the data\n",
    "    df = fix_date_index_write(df, arg_dict)\n",
    "    \n",
    "    # Returns the df and a list of all of the possible column names\n",
    "    return df, li_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Prepare arguments for driver\n",
    "    arg_dict = {'file_name_1': r'data\\all_df.csv',\n",
    "                'file_name_2': r'C:\\Users\\linds\\OneDrive\\mystuff\\GitHub\\covid\\data\\country_codes_edited.csv',\n",
    "                'feature': 'Alpha_3',\n",
    "                'place': 'USA',\n",
    "                'dependent_variable': 'Deaths',\n",
    "                'path': r'C:\\Users\\linds\\OneDrive\\mystuff\\GitHub\\COVID-19\\csse_covid_19_data\\csse_covid_19_daily_reports'}\n",
    "    \n",
    "    # Start driver\n",
    "    df, li_set = driver(arg_dict) # Want the list of column names in case they change\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
